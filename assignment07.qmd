---
title: "Assignment07"
author: "Benjamin Reese"
format: pdf
self-contained: true
---

# Exercise 01

## Runing Code to Create Dataset

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(tidymodels)

# use this url to download the data directly into R
df <- read_csv("https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv")

# clean names with janitor
sampled_df <- df %>% 
  janitor::clean_names() 

# create an inspection year variable
sampled_df <- sampled_df %>%
  mutate(inspection_date = mdy(inspection_date)) %>%
  mutate(inspection_year = year(inspection_date))

# get most-recent inspection
sampled_df <- sampled_df %>%
  group_by(camis) %>%
  filter(inspection_date == max(inspection_date)) %>%
  ungroup()

# subset the data
sampled_df <- sampled_df %>%
  select(camis, boro, zipcode, cuisine_description, inspection_date,
         action, violation_code, violation_description, grade,
         inspection_type, latitude, longitude, council_district,
         census_tract, inspection_year, critical_flag) %>%
  filter(complete.cases(.)) %>%
  filter(inspection_year >= 2017) %>%
  filter(grade %in% c("A", "B", "C")) 

# create the binary target variable
sampled_df <- sampled_df %>%
  mutate(grade = if_else(grade == "A", "A", "Not A")) %>%
  mutate(grade = as.factor(grade))

# create extra predictors
sampled_df <- sampled_df %>%
  group_by(boro, zipcode, cuisine_description, inspection_date,
           action, violation_code, violation_description, grade,
           inspection_type, latitude, longitude, council_district,
           census_tract, inspection_year)  %>%
  mutate(vermin = str_detect(violation_description, pattern = "mice|rats|vermin|roaches")) %>%
  summarize(violations = n(),
            vermin_types = sum(vermin),
            critical_flags = sum(critical_flag == "Y")) %>%
  ungroup()

# write the data
write_csv(sampled_df, "restaurant_grades.csv")

```


## 1. 

In this exercise, I split `sampled_df`, the restaurant data, into training and testing datasets, create a recipe, and estimate a decision tree model.

### a. Setting the Seed and Splitting the Dataset

```{r}
## Setting Seed
set.seed(20201020)

## Splitting the Sample
split <- initial_split(sampled_df, prop = 0.8)

## Training and Testing
restaurant_train <- training(split)
restaurant_test <- testing(split)
```

### b. Creating the Recipe

```{r}
## Creating the Recipe
restaurant_rec <- 
  recipe(grade ~ ., data = restaurant_train) %>%
  themis::step_downsample(grade)
```

### c. Code for the Decision Tree

```{r}
## Creating the CART Model
cart_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")

## Workflow
cart_wf <- workflow() %>%
  add_recipe(restaurant_rec) %>%
  add_model(cart_mod)

## Estimating the Model
cart_fit <- cart_wf %>%
  fit(data = restaurant_train)
```

## 2.

The code below evaluates the model by generating a confusion matrix and calculates precision and sensitivey. A written description of the quality of the model is also included. 

## Creating predictions tibble

```{r}
## Selecting the Predictions
predictions <- bind_cols(
  restaurant_test,
  predict(object = cart_fit, new_data = restaurant_test),
  predict(object = cart_fit, new_data = restaurant_test, type = "prob")
) %>%
  mutate(color=as.factor(grade))

## The Predictions
select(predictions, grade, starts_with(".pred"))
```

### a. Confusion Matrix

```{r}
## Confusion matrix
conf_mat(data = predictions, truth = grade, estimate = .pred_class)
```

### b. Calculating Precision & Recall

```{r}
## Precision
precision(data = predictions, truth = grade, estimate = .pred_class)

## Recall/Sensitivity
recall(data = predictions, truth = grade, estimate = .pred_class)

```

### c.

The model's precision, or how often the classifier is correct when it predicts an event, is very high, .998. This high level of precision means that the model is very good at predicting an event when there is an event. In this case, our models is highly precise when predicting a restaurant has an A rating when it actually has an A rating. The model's sensitivity, or how often the classifier is correct when there is an event is not as high as its precision, meaning that there are many restaurants that have an A rating, but the model is predicting that they do not have an A rating. Overall, the quality of the model depends on its intended use and the relative costs associated with its use. If the model predicts an A rating, then we can be pretty sure the result is not a false positive, but we will see many false negatives. 

## 3. 

Using a *KNN*, or K-nearest neighbors, algorithm instead of the decision tree algorithm may improve the quality of the model. Instead of dividing the data into two or more sets as the decision tree model does, a *KNN* algorithm stores all available cases and classifies new cases by taking a majority vote of its k neighbors. This majority vote may prove more accurate than the binary dividing of the decision tree model.

## 4. Plot for Variable Importance

```{r}
library(vip)

cart_fit %>%
  extract_fit_parsnip() %>%
  vip(num_features = 10)

```

Variable, or feature, importance in decision tree models is calculated by finding the decrease in the Gini impurity weighted by the probability of reaching that node. Node probability is the proportion of samples that reach a node out of the total samples. The most important variables in a decision tree model are the variables associated with the most Gini impurity being eliminated at each branch of the decision tree. In other words, the variable with the highest value of the decrease in impurity, weighted by the probability of the sample making it to a node, is the most important feature.

In the model above, the most important feature is the inspection type. Location, defined by the Census tract the restaurant is located in was the second most important variable. These two are followed by a series of variables relation to the types of violations associated with a restaurant, the type of cuisine, and the date of the inspection. The most important feature, inspection type, is a categorical variable largely divided between initial and re-inspections. It is unsurprising that the most important predictor of a rating is the type of inspection because the rating is a direct result of an inspection, and the exact circumstances of an inspection surely dictate the ensuing ratings. It is also possible that restaurants fix violations and receive A ratings on subsequent visits and re-inspections, meaning re-inspection will predict A ratings.

## 5. 

Restaurants that receive low ratings will want to correct their violations and try to raise their grade, but this requires an initial inspection. If restaurants correct after a rating, then the focus should be on casting a large net and reaching as many restaurants as possible, even foregoing continued visits at established businesses, in order to encourage restaurants to improve their health safety conditions. Also, location is one of the most important predictors of grade as well, so spending time inspecting restaurants in locations that are associated with low health inspection ratings will be an optimal use of health department resources.

# Exercise 2

## Running Code From Assignment

```{r}
Chicago_modeling <- Chicago %>%
slice(1:5678)

Chicago_implementation <- Chicago %>%
slice(5679:5698) %>%
select(-ridership)
```

## 1. Converting Date into Useable Variable

```{r}
## Loading Lubridate
library(lubridate)

## Converting Dates
Chicago_modeling <- Chicago_modeling %>%
  mutate(weekday = wday(date, label = TRUE), 
         month = month(date, label = TRUE),
         yearday = yday(date)
  )

```

## 2. Setting up the testing enviroment

## a. Setting the Seed and Splitting Modeling Data into Training & Testing

```{r}
## Setting seed
set.seed(20211101)

## Splitting
split <- initial_split(data = Chicago_modeling)

## Training and Testing
chicago_train <- training(x = split)
chicago_test <- testing(x = split)
```

## b. Exploratory Data Analysis

```{r, warning=FALSE, message=FALSE}
## Counting Daily Ridership
chicago_train %>%
  group_by(weekday) %>%
  summarise(avg_daily_ridership = mean(Clark_Lake))


## Daily Average Ridership Plot
chicago_train %>%
  group_by(weekday) %>%
  summarise(avg_daily_ridership = mean(Clark_Lake)) %>%
  ggplot(aes(x=weekday, y=avg_daily_ridership, fill=weekday)) +
  geom_col() +
  theme_minimal() +
  labs(title = "Daily Ridership for Chicago's Clark-Lake Station", 
       x = "Weekday", y = "Average Daily Ridership", fill="Weekday",
       subtitle = "Ridership Peaks During Working Week, Drops off During Weekend")

## Ridership During Games
chicago_train %>%
  mutate(game = case_when(
    Blackhawks_Home == 1 ~ "Blackhawks",
    Bulls_Home == 1 ~ "Bulls",
    Bears_Home == 1 ~ "Bears",
    WhiteSox_Home == 1 ~ "White Sox",
    Cubs_Home == 1 ~ "Cubs",
    Blackhawks_Home == 0 ~ "Away",
    Bulls_Home == 0 ~ "Away",
    Bears_Home == 0 ~ "Away",
    WhiteSox_Home == 0 ~ "Away",
    Cubs_Home == 0 ~ "Away",
  )) %>%
  group_by(game) %>%
  summarise(avg_gametime_ridership = mean(Clark_Lake))

## Ridership During Games Plot
chicago_train %>%
  mutate(game = case_when(
    Blackhawks_Home == 1 ~ "Blackhawks",
    Bulls_Home == 1 ~ "Bulls",
    Bears_Home == 1 ~ "Bears",
    WhiteSox_Home == 1 ~ "White Sox",
    Cubs_Home == 1 ~ "Cubs",
    Blackhawks_Home == 0 ~ "Away",
    Bulls_Home == 0 ~ "Away",
    Bears_Home == 0 ~ "Away",
    WhiteSox_Home == 0 ~ "Away",
    Cubs_Home == 0 ~ "Away",
  )) %>%
  group_by(game) %>%
  summarise(avg_gametime_ridership = mean(Clark_Lake)) %>%
  ggplot(aes(x=game, y=avg_gametime_ridership, fill=game)) +
  geom_col() +
  theme_minimal() +
  labs(title = "Gametime Ridership for Chicago's Clark-Lake Station", 
       x = "Team", y = "Average Ridership", fill="Team",
       subtitle = "Ridership Dips When Bears Have Home Game")

## Ridership During Inclement Weather
chicago_train %>%
  mutate(weather = case_when(
    weather_rain > 0 ~ "Rain",
    weather_snow > 0 ~ "Snow",
    weather_cloud > 0 ~ "Cloud",
    weather_storm > 0 ~ "Storm",
    weather_rain == 0 ~ "Sunny",
    weather_snow == 0 ~ "Sunny",
    weather_cloud == 0 ~ "Sunny",
    weather_storm == 0 ~ "Sunny",
  )) %>%
  group_by(weather) %>%
  summarise(weather_ridership = mean(Clark_Lake))

chicago_train %>%
  mutate(weather = case_when(
    weather_rain > 0 ~ "Rain",
    weather_snow > 0 ~ "Snow",
    weather_cloud > 0 ~ "Cloud",
    weather_storm > 0 ~ "Storm",
    weather_rain == 0 ~ "Sunny",
    weather_snow == 0 ~ "Sunny",
    weather_cloud == 0 ~ "Sunny",
    weather_storm == 0 ~ "Sunny",
  )) %>%
  group_by(weather) %>%
  summarise(weather_ridership = mean(Clark_Lake)) %>%
  ggplot(aes(x=weather, y=weather_ridership, fill=weather_ridership)) + 
  geom_col() +
  theme_minimal() +
  labs(title = "Inclement Weather Ridership for Chicago's Clark-Lake Station", 
       x = "Weather", y = "Average Ridership",
       subtitle = "Weather is Not A Strong Predictor of Ridership") +
  theme(legend.position="none")

## Relationship Between Weather and Ridership
chicago_train %>%
  ggplot(aes(x=temp, y=Clark_Lake)) +
  geom_point(alpha=.3) +
  geom_smooth() +
  theme_minimal() +
  labs(title = "Relationship Between Temperature and Ridership at Clark-Lake Station", 
       x = "Temperature (F)", y = "Ridership")
  

```
## c. Setting up v-fold cross validation

```{r}
## Setting up folds
folds <- vfold_cv(data = data_train, v = 10)
```



